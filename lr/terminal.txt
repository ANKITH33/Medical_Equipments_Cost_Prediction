uv run preproc.py
Starting preprocessing...
================================================================================
Loading datasets...
Original train shape: (5000, 20)
Original test shape: (500, 19)

Dropping columns: ['Hospital_Id', 'Supplier_Name', 'Hospital_Location', 'Order_Placed_Date', 'Delivery_Date']
After dropping columns - Train shape: (5000, 15)
After dropping columns - Test shape: (500, 14)

Features train shape: (5000, 14)
Features test shape: (500, 14)

Categorical columns in train: ['Equipment_Type', 'CrossBorder_Shipping', 'Urgent_Shipping', 'Installation_Service', 'Transport_Method', 'Fragile_Equipment', 'Hospital_Info', 'Rural_Hospital']
Categorical columns in test: ['Equipment_Type', 'CrossBorder_Shipping', 'Urgent_Shipping', 'Installation_Service', 'Transport_Method', 'Fragile_Equipment', 'Hospital_Info', 'Rural_Hospital']
All categorical columns to encode: ['Rural_Hospital', 'Equipment_Type', 'Transport_Method', 'Installation_Service', 'Hospital_Info', 'CrossBorder_Shipping', 'Urgent_Shipping', 'Fragile_Equipment']

Combining datasets for consistent one-hot encoding...
Combined dataset shape: (5500, 15)

Performing one-hot encoding...
Encoding columns: ['Rural_Hospital', 'Equipment_Type', 'Transport_Method', 'Installation_Service', 'Hospital_Info', 'CrossBorder_Shipping', 'Urgent_Shipping', 'Fragile_Equipment']
Shape after one-hot encoding: (5500, 37)

Final train features shape: (5000, 36)
Final test features shape: (500, 36)

Columns in train but not in test: set()
Columns in test but not in train: set()
Total common columns: 36

Final shapes with same columns:
X_train: (5000, 36)
X_test: (500, 36)

Final columns (36):
  1. Base_Transport_Fee
  2. CrossBorder_Shipping_No
  3. CrossBorder_Shipping_Yes
  4. CrossBorder_Shipping_nan
  5. Equipment_Height
  6. Equipment_Type_Aluminium
  7. Equipment_Type_Brass
  8. Equipment_Type_Bronze
  9. Equipment_Type_Clay
 10. Equipment_Type_Marble
 11. Equipment_Type_Stone
 12. Equipment_Type_Wood
 13. Equipment_Type_nan
 14. Equipment_Value
 15. Equipment_Weight
 16. Equipment_Width
 17. Fragile_Equipment_No
 18. Fragile_Equipment_Yes
 19. Fragile_Equipment_nan
 20. Hospital_Info_Wealthy
 21. Hospital_Info_Working Class
 22. Hospital_Info_nan
 23. Installation_Service_No
 24. Installation_Service_Yes
 25. Installation_Service_nan
 26. Rural_Hospital_No
 27. Rural_Hospital_Yes
 28. Rural_Hospital_nan
 29. Supplier_Reliability
 30. Transport_Method_Airways
 31. Transport_Method_Roadways
 32. Transport_Method_Waterways
 33. Transport_Method_nan
 34. Urgent_Shipping_No
 35. Urgent_Shipping_Yes
 36. Urgent_Shipping_nan

Data types after preprocessing:
TRAIN:
bool       30
float64     6
Name: count, dtype: int64

TEST:
bool       30
float64     6
Name: count, dtype: int64

Missing values after preprocessing:
TRAIN:
Total missing: 1773
Columns with missing values:
Equipment_Height        283
Equipment_Weight        460
Equipment_Width         443
Supplier_Reliability    587
dtype: int64

TEST:
Total missing: 186
Columns with missing values:
Equipment_Height        23
Equipment_Weight        52
Equipment_Width         56
Supplier_Reliability    55
dtype: int64

================================================================================
PREPROCESSING COMPLETE!
================================================================================

Target variable (y_train) shape: (5000,)
Target variable stats:
  Mean: 17898.06
  Std: 255426.13
  Min: -588183.20
  Max: 11143428.25

Saving processed datasets...
Saved files:
- X_train_preprocessed.csv
- X_test_preprocessed.csv
- y_train.csv

Preprocessing script completed successfully!
(ml-env) ➜  mlnew uv run tc_analysis.py
Loading target variable...
Target variable shape: (5000,)
Target variable name: Transport_Cost

============================================================
TRANSPORT COST DISTRIBUTION ANALYSIS
============================================================
Count: 5000
Mean: 17,898.06
Median: 377.61
Std: 255,426.13
Min: -588,183.20
Max: 11,143,428.25
Skewness: 30.266
Kurtosis: 1116.291

Percentiles:
 1th percentile:    -5,503.16
 5th percentile:      -432.17
10th percentile:        97.42
25th percentile:       188.41
50th percentile:       377.61
75th percentile:     1,182.70
90th percentile:     5,412.85
95th percentile:    19,034.92
99th percentile:   252,555.97

Negative values: 493 (9.86%)
Zero values: 0 (0.00%)

Outliers (IQR method): 914 (18.28%)
IQR bounds: [-1,303.02, 2,674.13]

============================================================
OUTLIER ANALYSIS FOR DIFFERENT PERCENTILES
============================================================

Removing 2.5th and 97.5th percentile outliers:
  Thresholds: [-1,313.72, 55,947.11]
  Outliers removed: 250 (5.0%)
  Remaining samples: 4750 (95.0%)
  Filtered mean: 2,042.81
  Filtered std: 5,991.82
  Filtered min: -1,312.68
  Filtered max: 55,860.52

Removing 5th and 95th percentile outliers:
  Thresholds: [-432.17, 19,034.92]
  Outliers removed: 500 (10.0%)
  Remaining samples: 4500 (90.0%)
  Filtered mean: 1,245.29
  Filtered std: 2,510.25
  Filtered min: -432.13
  Filtered max: 19,033.53

Removing 10th and 90th percentile outliers:
  Thresholds: [97.42, 5,412.85]
  Outliers removed: 1000 (20.0%)
  Remaining samples: 4000 (80.0%)
  Filtered mean: 786.05
  Filtered std: 990.96
  Filtered min: 97.46
  Filtered max: 5,412.36

Removing 1th and 99th percentile outliers:
  Thresholds: [-5,503.16, 252,555.97]
  Outliers removed: 100 (2.0%)
  Remaining samples: 4900 (98.0%)
  Filtered mean: 3,915.67
  Filtered std: 18,167.72
  Filtered min: -5,502.32
  Filtered max: 252,450.21
/mnt/data/home/dhruv/Desktop/mlnew/tc_analysis.py:167: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.
  axes[1].boxplot(data_to_plot, labels=labels)

============================================================
ANALYSIS COMPLETE!
============================================================
Plots saved:
- transport_cost_distribution.png
- transport_cost_outlier_analysis.png
(ml-env) ➜  mlnew uv run remove_outliers.py
Starting outlier removal...
================================================================================
Loading preprocessed data...
Original shapes:
X_train: (5000, 36)
y_train: (5000,)

Target variable (Transport_Cost) statistics:
Mean: 17898.06
Std: 255426.13
Min: -588183.20
Max: 11143428.25

Percentile thresholds:
2.5th percentile (lower threshold): -1313.72
97.5th percentile (upper threshold): 55947.11

Outlier analysis:
Lower outliers (≤ -1313.72): 125
Upper outliers (≥ 55947.11): 125
Total outliers: 250
Percentage of data to remove: 5.00%

After removing outliers:
X_train shape: (4750, 36)
y_train shape: (4750,)
Rows removed: 250
Rows remaining: 4750

New target variable statistics (after outlier removal):
Mean: 2042.81
Std: 5991.82
Min: -1312.68
Max: 55860.52
Skewness: 5.43

Percentiles of cleaned target variable:
 1th percentile: -732.80
 5th percentile: -230.41
10th percentile: 122.22
25th percentile: 193.16
50th percentile: 377.61
75th percentile: 1068.24
90th percentile: 4084.06
95th percentile: 9592.21
99th percentile: 36884.31

Missing values in filtered X_train:
Total missing values: 1682
Columns with missing values:
  Equipment_Height: 271 (5.71%)
  Equipment_Weight: 437 (9.20%)
  Equipment_Width: 419 (8.82%)
  Supplier_Reliability: 555 (11.68%)

================================================================================
OUTLIER REMOVAL COMPLETE!
================================================================================

Saving cleaned datasets...
Saved files:
- X_train_clean.csv
- y_train_clean.csv

Data reduction summary:
Original samples: 5000
Samples after outlier removal: 4750
Reduction: 250 samples (5.00%)

Outlier removal completed successfully!
(ml-env) ➜  mlnew uv run remove_outliers_2.py
Starting outlier removal...
================================================================================
Loading preprocessed data...
Original shapes:
X_train: (5000, 36)
y_train: (5000,)

Target variable (Transport_Cost) statistics:
Mean: 17898.06
Std: 255426.13
Min: -588183.20
Max: 11143428.25

Percentile thresholds:
2.5th percentile (lower threshold): -1313.72
97.5th percentile (upper threshold): 55947.11

Outlier analysis:
Lower outliers (≤ -1313.72): 125
Upper outliers (≥ 55947.11): 125
Total outliers: 250
Percentage of data to remove: 5.00%

After removing outliers:
X_train shape: (4750, 36)
y_train shape: (4750,)
Rows removed: 250
Rows remaining: 4750

New target variable statistics (after outlier removal):
Mean: 2042.81
Std: 5991.82
Min: -1312.68
Max: 55860.52
Skewness: 5.43

Percentiles of cleaned target variable:
 1th percentile: -732.80
 5th percentile: -230.41
10th percentile: 122.22
25th percentile: 193.16
50th percentile: 377.61
75th percentile: 1068.24
90th percentile: 4084.06
95th percentile: 9592.21
99th percentile: 36884.31

Missing values in filtered X_train:
Total missing values: 1682
Columns with missing values:
  Equipment_Height: 271 (5.71%)
  Equipment_Weight: 437 (9.20%)
  Equipment_Width: 419 (8.82%)
  Supplier_Reliability: 555 (11.68%)

================================================================================
OUTLIER REMOVAL COMPLETE!
================================================================================

Overwriting preprocessed datasets with outlier-free data...
Updated files:
- X_train_preprocessed.csv (outliers removed)
- y_train.csv (outliers removed)

Data reduction summary:
Original samples: 5000
Samples after outlier removal: 4750
Reduction: 250 samples (5.00%)

Outlier removal completed successfully!
Preprocessed files have been updated with cleaned data.
(ml-env) ➜  mlnew uv run impute_3.py
Starting numerical imputation...
================================================================================
Loading preprocessed data...
Loaded shapes:
X_train: (4750, 36)
X_test: (500, 36)
y_train: (4750, 1)

Numerical columns identified: ['Base_Transport_Fee', 'Equipment_Height', 'Equipment_Value', 'Equipment_Weight', 'Equipment_Width', 'Supplier_Reliability']

Missing values BEFORE imputation:
TRAIN:
  Equipment_Height: 271 (5.71%)
  Equipment_Weight: 437 (9.20%)
  Equipment_Width: 419 (8.82%)
  Supplier_Reliability: 555 (11.68%)

TEST:
  Equipment_Height: 23 (4.60%)
  Equipment_Weight: 52 (10.40%)
  Equipment_Width: 56 (11.20%)
  Supplier_Reliability: 55 (11.00%)

Calculating median values from train set...
  Equipment_Height: median = 20.0000
  Equipment_Weight: median = 2628.0000
  Equipment_Width: median = 8.0000
  Supplier_Reliability: median = 0.4400

Imputing train set...
  Equipment_Height: 271 -> 0 missing values
  Equipment_Weight: 437 -> 0 missing values
  Equipment_Width: 419 -> 0 missing values
  Supplier_Reliability: 555 -> 0 missing values

Imputing test set with same median values...
  Equipment_Height: 23 -> 0 missing values
  Equipment_Weight: 52 -> 0 missing values
  Equipment_Width: 56 -> 0 missing values
  Supplier_Reliability: 55 -> 0 missing values

Missing values AFTER imputation:
TRAIN:
  Total missing in numerical columns: 0

TEST:
  Total missing in numerical columns: 0

Total missing values in entire datasets after imputation:
Train: 0
Test: 0

Statistics of imputed numerical columns (train set):

Equipment_Height:
  Mean: 21.0356
  Median: 20.0000
  Std: 11.3138
  Min: 3.0000
  Max: 73.0000

Equipment_Weight:
  Mean: 145436.3813
  Median: 2628.0000
  Std: 750681.0213
  Min: 3.0000
  Max: 17704429.0000

Equipment_Width:
  Mean: 9.1421
  Median: 8.0000
  Std: 4.8974
  Min: 2.0000
  Max: 50.0000

Supplier_Reliability:
  Mean: 0.4516
  Median: 0.4400
  Std: 0.2494
  Min: 0.0000
  Max: 1.0000

================================================================================
NUMERICAL IMPUTATION COMPLETE!
================================================================================

Saving imputed datasets...
Updated files:
- X_train_preprocessed.csv (numerical features imputed)
- X_test_preprocessed.csv (numerical features imputed)
- y_train.csv

Imputation summary:
Median values used for imputation:
  Equipment_Height: 20.0000
  Equipment_Weight: 2628.0000
  Equipment_Width: 8.0000
  Supplier_Reliability: 0.4400

Final dataset shapes:
X_train: (4750, 36)
X_test: (500, 36)

Numerical imputation completed successfully!
All numerical missing values have been filled with train set medians.
(ml-env) ➜  mlnew uv run check_nan_4.py
CHECKING FOR NaN VALUES IN PREPROCESSED DATASETS
============================================================
Loading preprocessed datasets...
Dataset shapes:
X_train: (4750, 36)
X_test: (500, 36)
y_train: (4750, 1)
============================================================
CHECKING X_TRAIN FOR NaN VALUES:
----------------------------------------
Total NaN values in X_train: 0
✓ No NaN values found in X_train

CHECKING X_TEST FOR NaN VALUES:
----------------------------------------
Total NaN values in X_test: 0
✓ No NaN values found in X_test

CHECKING Y_TRAIN FOR NaN VALUES:
----------------------------------------
Total NaN values in y_train: 0
✓ No NaN values found in y_train

============================================================
SUMMARY:
Total NaN values across all datasets: 0
✓ SUCCESS: No NaN values found in any dataset!
✓ All datasets are ready for modeling.

ADDITIONAL CHECKS:
X_train data types: {dtype('bool'): 30, dtype('float64'): 6}
X_test data types: {dtype('bool'): 30, dtype('float64'): 6}
✓ X_train and X_test have identical column names

Column count: X_train=36, X_test=36
============================================================
NaN CHECK COMPLETE!
(ml-env) ➜  mlnew cd models
(ml-env) ➜  models uv run 1.py
Starting Ridge and Lasso model training...
================================================================================
Loading preprocessed data...
Traceback (most recent call last):
  File "/mnt/data/home/dhruv/Desktop/mlnew/models/1.py", line 170, in <module>
    results, models, best_model, submission, scaler = train_ridge_lasso_models()
                                                      ~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/mnt/data/home/dhruv/Desktop/mlnew/models/1.py", line 19, in train_ridge_lasso_models
    X_train = pd.read_csv('X_train_preprocessed.csv')
  File "/home/dhruv/miniconda3/envs/ml-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/dhruv/miniconda3/envs/ml-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/dhruv/miniconda3/envs/ml-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "/home/dhruv/miniconda3/envs/ml-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py", line 1880, in _make_engine
    self.handles = get_handle(
                   ~~~~~~~~~~^
        f,
        ^^
    ...<6 lines>...
        storage_options=self.options.get("storage_options", None),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/dhruv/miniconda3/envs/ml-env/lib/python3.13/site-packages/pandas/io/common.py", line 873, in get_handle
    handle = open(
        handle,
    ...<3 lines>...
        newline="",
    )
FileNotFoundError: [Errno 2] No such file or directory: 'X_train_preprocessed.csv'
(ml-env) ➜  models cd ..
cd: no such file or directory: ..
(ml-env) ➜  models cd
(ml-env) ➜  ~ cd Desktop
(ml-env) ➜  Desktop cd mlnew
(ml-env) ➜  mlnew ls
check_nan_4.py  preproc_old.py        X_test_preprocessed.csv
eda_irr.py      remove_outliers_2.py  X_train_preprocessed.csv
impute_3.py     tc_analysis_1.py      y_train.csv
model1.py       test.csv
preproc_0.py    train.csv
(ml-env) ➜  mlnew uv run model1.py
(ml-env) ➜  mlnew uv run model1.py
Starting Ridge and Lasso model training...
================================================================================
Loading preprocessed data...
Dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Standardizing features...
Features standardized using StandardScaler

Training models...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 16997343.60, RMSE: 4122.78, MAE: 1733.41, R²: 0.5520
  Val   - MSE: 7948577.94, RMSE: 2819.32, MAE: 1389.72, R²: 0.6715

Training Lasso...
Lasso Results:
  Train - MSE: 16997371.88, RMSE: 4122.79, MAE: 1732.07, R²: 0.5520
  Val   - MSE: 7947126.86, RMSE: 2819.06, MAE: 1388.50, R²: 0.6716

============================================================
MODEL COMPARISON:
============================================================
Ridge:
  Validation RMSE: 2819.32
  Validation R²: 0.6715
Lasso:
  Validation RMSE: 2819.06
  Validation R²: 0.6716

Best model: Lasso (Validation RMSE: 2819.06)

Loading original test data for Hospital_Id...
Making predictions on test set with Lasso...

Submission file created:
Shape: (500, 2)
Columns: ['Hospital_Id', 'Transport_Cost']

First few predictions:
            Hospital_Id  Transport_Cost
0          fffe33003400     1394.255947
1  fffe3700330036003600     1649.618368
2  fffe3300390038003400     5161.657941
3      fffe310030003900     -217.124307
4  fffe3700330031003200     2031.073177

Prediction statistics:
Mean: 3271.75
Std: 11512.10
Min: -2275.91
Max: 170863.06

Submission saved to 'submission.csv'

================================================================================
MODEL TRAINING COMPLETE!
================================================================================

Final Results Summary:
Best model: Lasso
Submission file: submission.csv (500 predictions)

Files created:
- submission.csv

Training completed successfully!
(ml-env) ➜  mlnew uv run model1.py
Starting Ridge and Lasso model training...
================================================================================
Loading preprocessed data...
Dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Standardizing features...
Features standardized using StandardScaler

Training models...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 17007920.90, RMSE: 4124.07, MAE: 1729.29, R²: 0.5517
  Val   - MSE: 7808193.66, RMSE: 2794.31, MAE: 1382.50, R²: 0.6773

Training Lasso...
Lasso Results:
  Train - MSE: 17000521.94, RMSE: 4123.17, MAE: 1720.02, R²: 0.5519
  Val   - MSE: 7923143.68, RMSE: 2814.81, MAE: 1377.33, R²: 0.6726

============================================================
MODEL COMPARISON:
============================================================
Ridge:
  Validation RMSE: 2794.31
  Validation R²: 0.6773
Lasso:
  Validation RMSE: 2814.81
  Validation R²: 0.6726

Best model: Ridge (Validation RMSE: 2794.31)

Loading original test data for Hospital_Id...
Making predictions on test set with Ridge...

Submission file created:
Shape: (500, 2)
Columns: ['Hospital_Id', 'Transport_Cost']

First few predictions:
            Hospital_Id  Transport_Cost
0          fffe33003400     1401.184880
1  fffe3700330036003600     1605.810081
2  fffe3300390038003400     5233.096989
3      fffe310030003900     -200.314122
4  fffe3700330031003200     2019.043568

Prediction statistics:
Mean: 3254.37
Std: 11243.55
Min: -2241.65
Max: 165048.82

Submission saved to 'submission.csv'

================================================================================
MODEL TRAINING COMPLETE!
================================================================================

Final Results Summary:
Best model: Ridge
Submission file: submission.csv (500 predictions)

Files created:
- submission.csv

Training completed successfully!
(ml-env) ➜  mlnew uv run model1.py
Starting Ridge and Lasso model training...
================================================================================
Loading preprocessed data...
Dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Standardizing features...
Features standardized using StandardScaler

Training models...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 17457587.22, RMSE: 4178.23, MAE: 1696.04, R²: 0.5399
  Val   - MSE: 7294015.44, RMSE: 2700.74, MAE: 1328.77, R²: 0.6986

Training Lasso...
Lasso Results:
  Train - MSE: 17000521.94, RMSE: 4123.17, MAE: 1720.02, R²: 0.5519
  Val   - MSE: 7923143.68, RMSE: 2814.81, MAE: 1377.33, R²: 0.6726

============================================================
MODEL COMPARISON:
============================================================
Ridge:
  Validation RMSE: 2700.74
  Validation R²: 0.6986
Lasso:
  Validation RMSE: 2814.81
  Validation R²: 0.6726

Best model: Ridge (Validation RMSE: 2700.74)

Loading original test data for Hospital_Id...
Making predictions on test set with Ridge...

Submission file created:
Shape: (500, 2)
Columns: ['Hospital_Id', 'Transport_Cost']

First few predictions:
            Hospital_Id  Transport_Cost
0          fffe33003400     1385.100032
1  fffe3700330036003600     1417.116860
2  fffe3300390038003400     5469.622104
3      fffe310030003900      -83.472500
4  fffe3700330031003200     1967.381785

Prediction statistics:
Mean: 3125.11
Std: 9640.85
Min: -1842.13
Max: 133995.42

Submission saved to 'submission.csv'

================================================================================
MODEL TRAINING COMPLETE!
================================================================================

Final Results Summary:
Best model: Ridge
Submission file: submission.csv (500 predictions)

Files created:
- submission.csv

Training completed successfully!
(ml-env) ➜  mlnew uv run model2.py
Starting Ridge and Lasso model training with polynomial features...
================================================================================
Loading preprocessed data...
Original dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Creating polynomial features (degree=2)...
Fitting polynomial transformer on training data...
Transforming validation and test data...
After polynomial features:
X_train_poly: (4037, 702)
X_val_poly: (713, 702)
X_test_poly: (500, 702)
Feature expansion: 36 -> 702 features

Standardizing polynomial features...
Features standardized using StandardScaler

Training models with polynomial features...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 10532806.74, RMSE: 3245.43, MAE: 1261.78, R²: 0.7224
  Val   - MSE: 15079412.32, RMSE: 3883.22, MAE: 1291.57, R²: 0.3769

Training Lasso...
Lasso Results:
  Train - MSE: 10727432.29, RMSE: 3275.28, MAE: 1186.51, R²: 0.7173
  Val   - MSE: 13171876.22, RMSE: 3629.31, MAE: 1172.79, R²: 0.4557
  Features selected by Lasso: 177/702

============================================================
MODEL COMPARISON:
============================================================
Ridge:
  Validation RMSE: 3883.22
  Validation R²: 0.3769
Lasso:
  Validation RMSE: 3629.31
  Validation R²: 0.4557

Best model: Lasso (Validation RMSE: 3629.31)

Loading original test data for Hospital_Id...
Making predictions on test set with Lasso...

Submission file created:
Shape: (500, 2)
Columns: ['Hospital_Id', 'Transport_Cost']

First few predictions:
            Hospital_Id  Transport_Cost
0          fffe33003400       80.101579
1  fffe3700330036003600      501.009952
2  fffe3300390038003400     4217.066430
3      fffe310030003900      535.774553
4  fffe3700330031003200     1482.897677

Prediction statistics:
Mean: 402.48
Std: 40823.31
Min: -835550.48
Max: 143108.87

Submission saved to 'submission_polynomial.csv'

================================================================================
MODEL TRAINING WITH POLYNOMIAL FEATURES COMPLETE!
================================================================================

Final Results Summary:
Best model: Lasso
Polynomial degree: 2
Original features: 36
Polynomial features: 702
Submission file: submission_polynomial.csv (500 predictions)

Files created:
- submission_polynomial.csv

Training with polynomial features completed successfully!
(ml-env) ➜  mlnew uv run model2.py
Starting Ridge and Lasso model training with polynomial features...
================================================================================
Loading preprocessed data...
Original dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Creating polynomial features (degree=2)...
Fitting polynomial transformer on training data...
Transforming validation and test data...
After polynomial features:
X_train_poly: (4037, 702)
X_val_poly: (713, 702)
X_test_poly: (500, 702)
Feature expansion: 36 -> 702 features

Standardizing polynomial features...
Features standardized using StandardScaler

Training models with polynomial features...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 12128884.54, RMSE: 3482.65, MAE: 1286.66, R²: 0.6803
  Val   - MSE: 6685398.79, RMSE: 2585.61, MAE: 1112.86, R²: 0.7237

Training Lasso...
Lasso Results:
  Train - MSE: 10727432.29, RMSE: 3275.28, MAE: 1186.51, R²: 0.7173
  Val   - MSE: 13171876.22, RMSE: 3629.31, MAE: 1172.79, R²: 0.4557
  Features selected by Lasso: 177/702

============================================================
MODEL COMPARISON:
============================================================
Ridge:
  Validation RMSE: 2585.61
  Validation R²: 0.7237
Lasso:
  Validation RMSE: 3629.31
  Validation R²: 0.4557

Best model: Ridge (Validation RMSE: 2585.61)

Loading original test data for Hospital_Id...
Making predictions on test set with Ridge...

Submission file created:
Shape: (500, 2)
Columns: ['Hospital_Id', 'Transport_Cost']

First few predictions:
            Hospital_Id  Transport_Cost
0          fffe33003400      200.229989
1  fffe3700330036003600      874.723669
2  fffe3300390038003400     6132.110891
3      fffe310030003900      643.077787
4  fffe3700330031003200     1772.204757

Prediction statistics:
Mean: 2837.10
Std: 8566.16
Min: -59874.52
Max: 103921.32

Submission saved to 'submission_polynomial.csv'

Top 20 features by absolute coefficient value (Ridge):
 1. Equipment_Value^2: -876.4354
 2. Base_Transport_Fee Supplier_Reliability: 682.0654
 3. Equipment_Weight Supplier_Reliability: 676.3568
 4. Equipment_Value Supplier_Reliability: 465.4612
 5. Equipment_Height Equipment_Value: 424.1770
 6. CrossBorder_Shipping_Yes Equipment_Value: 389.3929
 7. Equipment_Height Supplier_Reliability: 384.1009
 8. Equipment_Value Urgent_Shipping_Yes: 382.1592
 9. Equipment_Type_Marble Supplier_Reliability: 365.6075
10. Base_Transport_Fee Equipment_Value: 360.3091
11. Equipment_Height Equipment_Type_Stone: 335.2789
12. Equipment_Value Transport_Method_nan: 312.0373
13. Equipment_Value Equipment_Weight: -306.6834
14. Equipment_Height Equipment_Type_Marble: 296.2828
15. Equipment_Value Transport_Method_Airways: 295.3339
16. Equipment_Type_Stone Supplier_Reliability: 293.9008
17. Equipment_Type_Stone Equipment_Value: 279.5121
18. Equipment_Weight Urgent_Shipping_Yes: 277.5001
19. Equipment_Value: 273.3084
20. Equipment_Value Hospital_Info_Working Class: 245.7072

================================================================================
MODEL TRAINING WITH POLYNOMIAL FEATURES COMPLETE!
================================================================================

Final Results Summary:
Best model: Ridge
Polynomial degree: 2
Original features: 36
Polynomial features: 702
Submission file: submission_polynomial.csv (500 predictions)

Files created:
- submission_polynomial.csv

Training with polynomial features completed successfully!
(ml-env) ➜  mlnew uv run model2.py
Starting Ridge and Lasso model training with polynomial features...
================================================================================
Loading preprocessed data...
Original dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Creating polynomial features (degree=2)...
Fitting polynomial transformer on training data...
Transforming validation and test data...
After polynomial features:
X_train_poly: (4037, 702)
X_val_poly: (713, 702)
X_test_poly: (500, 702)
Feature expansion: 36 -> 702 features

Standardizing polynomial features...
Features standardized using StandardScaler

Training models with polynomial features...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 14978750.12, RMSE: 3870.24, MAE: 1458.08, R²: 0.6052
  Val   - MSE: 6235321.15, RMSE: 2497.06, MAE: 1136.66, R²: 0.7423

Training Lasso...
Lasso Results:
  Train - MSE: 37940291.93, RMSE: 6159.57, MAE: 2810.98, R²: 0.0000
  Val   - MSE: 24329903.51, RMSE: 4932.54, MAE: 2463.88, R²: -0.0054
  Features selected by Lasso: 0/702

============================================================
MODEL COMPARISON:
============================================================
Ridge:
  Validation RMSE: 2497.06
  Validation R²: 0.7423
Lasso:
  Validation RMSE: 4932.54
  Validation R²: -0.0054

Best model: Ridge (Validation RMSE: 2497.06)

Loading original test data for Hospital_Id...
Making predictions on test set with Ridge...

Submission file created:
Shape: (500, 2)
Columns: ['Hospital_Id', 'Transport_Cost']

First few predictions:
            Hospital_Id  Transport_Cost
0          fffe33003400      738.821178
1  fffe3700330036003600     1087.196636
2  fffe3300390038003400     5880.265308
3      fffe310030003900      187.243715
4  fffe3700330031003200     1757.443107

Prediction statistics:
Mean: 3286.88
Std: 10729.74
Min: -1225.26
Max: 162292.48

Submission saved to 'submission_polynomial.csv'

Top 20 features by absolute coefficient value (Ridge):
 1. Equipment_Weight Supplier_Reliability: 248.7837
 2. Equipment_Value Supplier_Reliability: 243.7029
 3. Equipment_Value Urgent_Shipping_Yes: 232.3841
 4. Base_Transport_Fee Supplier_Reliability: 217.4064
 5. Equipment_Height Equipment_Value: 203.6003
 6. Base_Transport_Fee Equipment_Value: 192.7214
 7. Equipment_Value: 188.1576
 8. Equipment_Value Transport_Method_Airways: 181.8860
 9. CrossBorder_Shipping_Yes Equipment_Value: 176.4997
10. Equipment_Value Fragile_Equipment_No: 172.2334
11. Equipment_Height Supplier_Reliability: 159.0393
12. Equipment_Weight Urgent_Shipping_Yes: 152.4947
13. Equipment_Value Equipment_Width: 149.3588
14. Equipment_Value Hospital_Info_Wealthy: 148.9236
15. Equipment_Type_nan Equipment_Value: 146.1335
16. Equipment_Type_Stone Equipment_Value: 136.1861
17. Equipment_Value Hospital_Info_Working Class: 135.1870
18. Equipment_Value Installation_Service_No: 134.1696
19. Equipment_Value Rural_Hospital_No: 132.5755
20. Equipment_Value Transport_Method_nan: 131.2635

================================================================================
MODEL TRAINING WITH POLYNOMIAL FEATURES COMPLETE!
================================================================================

Final Results Summary:
Best model: Ridge
Polynomial degree: 2
Original features: 36
Polynomial features: 702
Submission file: submission_polynomial.csv (500 predictions)

Files created:
- submission_polynomial.csv

Training with polynomial features completed successfully!
(ml-env) ➜  mlnew uv run model2.py
Starting Ridge and Lasso model training with polynomial features...
================================================================================
Loading preprocessed data...
Original dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Creating polynomial features (degree=2)...
Fitting polynomial transformer on training data...
Transforming validation and test data...
After polynomial features:
X_train_poly: (4037, 702)
X_val_poly: (713, 702)
X_test_poly: (500, 702)
Feature expansion: 36 -> 702 features

Standardizing polynomial features...
Features standardized using StandardScaler

Training models with polynomial features...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 14978750.12, RMSE: 3870.24, MAE: 1458.08, R²: 0.6052
  Val   - MSE: 6235321.15, RMSE: 2497.06, MAE: 1136.66, R²: 0.7423

Training Lasso...
Lasso Results:
  Train - MSE: 37940291.93, RMSE: 6159.57, MAE: 2810.98, R²: 0.0000
  Val   - MSE: 24329903.51, RMSE: 4932.54, MAE: 2463.88, R²: -0.0054
  Features selected by Lasso: 0/702

============================================================
MODEL COMPARISON:
============================================================
Ridge:
  Validation RMSE: 2497.06
  Validation R²: 0.7423
Lasso:
  Validation RMSE: 4932.54
  Validation R²: -0.0054

Best model: Ridge (Validation RMSE: 2497.06)

Loading original test data for Hospital_Id...
Making predictions on test set with Ridge...

Submission file created:
Shape: (500, 2)
Columns: ['Hospital_Id', 'Transport_Cost']

First few predictions:
            Hospital_Id  Transport_Cost
0          fffe33003400      738.821178
1  fffe3700330036003600     1087.196636
2  fffe3300390038003400     5880.265308
3      fffe310030003900      187.243715
4  fffe3700330031003200     1757.443107

Prediction statistics:
Mean: 3286.88
Std: 10729.74
Min: -1225.26
Max: 162292.48

Submission saved to 'submission_polynomial.csv'

Top 20 features by absolute coefficient value (Ridge):
 1. Equipment_Weight Supplier_Reliability: 248.7837
 2. Equipment_Value Supplier_Reliability: 243.7029
 3. Equipment_Value Urgent_Shipping_Yes: 232.3841
 4. Base_Transport_Fee Supplier_Reliability: 217.4064
 5. Equipment_Height Equipment_Value: 203.6003
 6. Base_Transport_Fee Equipment_Value: 192.7214
 7. Equipment_Value: 188.1576
 8. Equipment_Value Transport_Method_Airways: 181.8860
 9. CrossBorder_Shipping_Yes Equipment_Value: 176.4997
10. Equipment_Value Fragile_Equipment_No: 172.2334
11. Equipment_Height Supplier_Reliability: 159.0393
12. Equipment_Weight Urgent_Shipping_Yes: 152.4947
13. Equipment_Value Equipment_Width: 149.3588
14. Equipment_Value Hospital_Info_Wealthy: 148.9236
15. Equipment_Type_nan Equipment_Value: 146.1335
16. Equipment_Type_Stone Equipment_Value: 136.1861
17. Equipment_Value Hospital_Info_Working Class: 135.1870
18. Equipment_Value Installation_Service_No: 134.1696
19. Equipment_Value Rural_Hospital_No: 132.5755
20. Equipment_Value Transport_Method_nan: 131.2635

================================================================================
MODEL TRAINING WITH POLYNOMIAL FEATURES COMPLETE!
================================================================================

Final Results Summary:
Best model: Ridge
Polynomial degree: 2
Original features: 36
Polynomial features: 702
Submission file: submission_polynomial.csv (500 predictions)

Files created:
- submission_polynomial.csv

Training with polynomial features completed successfully!
(ml-env) ➜  mlnew uv run model2.py
Starting Ridge and Lasso model training with polynomial features...
================================================================================
Loading preprocessed data...
Original dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Creating polynomial features (degree=2)...
Fitting polynomial transformer on training data...
Transforming validation and test data...
After polynomial features:
X_train_poly: (4037, 702)
X_val_poly: (713, 702)
X_test_poly: (500, 702)
Feature expansion: 36 -> 702 features

Standardizing polynomial features...
Features standardized using StandardScaler

Training models with polynomial features...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 10802761.49, RMSE: 3286.76, MAE: 1240.73, R²: 0.7153
  Val   - MSE: 10336141.18, RMSE: 3214.99, MAE: 1181.01, R²: 0.5729

Training Lasso...
^C^C^C^C^CTraceback (most recent call last):
  File "/mnt/data/home/dhruv/Desktop/mlnew/model2.py", line 202, in <module>
    results, models, best_model, submission, poly_transformer, scaler = train_ridge_lasso_with_polynomial()
  File "/mnt/data/home/dhruv/Desktop/mlnew/model2.py", line 92, in train_ridge_lasso_with_polynomial
    model.fit(X_train_scaled, y_train_split)
  File "/home/dhruv/miniconda3/envs/ml-env/lib/python3.13/site-packages/sklearn/base.py", line 1365, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/home/dhruv/miniconda3/envs/ml-env/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py", line 1084, in fit
    _, this_coef, this_dual_gap, this_iter = self.path(
  File "/home/dhruv/miniconda3/envs/ml-env/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 191, in wrapper
    return func(*args, **kwargs)
  File "/home/dhruv/miniconda3/envs/ml-env/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py", line 695, in enet_path
    model = cd_fast.enet_coordinate_descent(
KeyboardInterrupt
^C%                                                                                                                                           (ml-env) ➜  mlnew uv run model2.py
Starting Ridge and Lasso model training with polynomial features...
================================================================================
Loading preprocessed data...
Original dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Creating polynomial features (degree=2)...
Fitting polynomial transformer on training data...
Transforming validation and test data...
After polynomial features:
X_train_poly: (4037, 702)
X_val_poly: (713, 702)
X_test_poly: (500, 702)
Feature expansion: 36 -> 702 features

Standardizing polynomial features...
Features standardized using StandardScaler

Training models with polynomial features...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 10802761.49, RMSE: 3286.76, MAE: 1240.73, R²: 0.7153
  Val   - MSE: 10336141.18, RMSE: 3214.99, MAE: 1181.01, R²: 0.5729

Training Lasso...
Lasso Results:
  Train - MSE: 10521008.75, RMSE: 3243.61, MAE: 1257.43, R²: 0.7227
  Val   - MSE: 16778563.11, RMSE: 4096.16, MAE: 1318.22, R²: 0.3067
  Features selected by Lasso: 247/702

============================================================
MODEL COMPARISON:
============================================================
Ridge:
  Validation RMSE: 3214.99
  Validation R²: 0.5729
Lasso:
  Validation RMSE: 4096.16
  Validation R²: 0.3067

Best model: Ridge (Validation RMSE: 3214.99)

Loading original test data for Hospital_Id...
Making predictions on test set with Ridge...

Submission file created:
Shape: (500, 2)
Columns: ['Hospital_Id', 'Transport_Cost']

First few predictions:
            Hospital_Id  Transport_Cost
0          fffe33003400       55.610813
1  fffe3700330036003600      389.939074
2  fffe3300390038003400     5309.004537
3      fffe310030003900      753.394995
4  fffe3700330031003200     1513.065301

Prediction statistics:
Mean: 1365.93
Std: 25687.20
Min: -513939.73
Max: 136264.17

Submission saved to 'submission_polynomial.csv'

Top 20 features by absolute coefficient value (Ridge):
 1. Equipment_Value^2: -2999.0249
 2. Base_Transport_Fee Supplier_Reliability: 1185.8978
 3. Equipment_Weight Supplier_Reliability: 985.2510
 4. Equipment_Weight^2: 869.4753
 5. Equipment_Value Equipment_Weight: -739.2425
 6. Equipment_Value Transport_Method_nan: 697.5189
 7. Equipment_Height Supplier_Reliability: 674.9505
 8. Equipment_Value Hospital_Info_Working Class: 597.7694
 9. Equipment_Value Fragile_Equipment_Yes: 588.6019
10. Equipment_Height Equipment_Value: 581.8286
11. CrossBorder_Shipping_Yes Equipment_Value: 566.4969
12. Equipment_Weight Fragile_Equipment_Yes: -540.9793
13. Equipment_Value: 535.3672
14. Supplier_Reliability^2: 524.3679
15. Equipment_Value Supplier_Reliability: 520.7942
16. Equipment_Height Equipment_Type_Stone: 503.3667
17. Equipment_Type_Marble Supplier_Reliability: 485.6296
18. Equipment_Height Equipment_Type_Marble: 470.9265
19. Equipment_Value Urgent_Shipping_No: 445.9072
20. Equipment_Value Rural_Hospital_No: 441.9045

================================================================================
MODEL TRAINING WITH POLYNOMIAL FEATURES COMPLETE!
================================================================================

Final Results Summary:
Best model: Ridge
Polynomial degree: 2
Original features: 36
Polynomial features: 702
Submission file: submission_polynomial.csv (500 predictions)

Files created:
- submission_polynomial.csv

Training with polynomial features completed successfully!
(ml-env) ➜  mlnew uv run model2.py
Starting Ridge and Lasso model training with polynomial features...
================================================================================
Loading preprocessed data...
Original dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Creating polynomial features (degree=2)...
Fitting polynomial transformer on training data...
Transforming validation and test data...
After polynomial features:
X_train_poly: (4037, 702)
X_val_poly: (713, 702)
X_test_poly: (500, 702)
Feature expansion: 36 -> 702 features

Standardizing polynomial features...
Features standardized using StandardScaler

Training models with polynomial features...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 10015597.88, RMSE: 3164.74, MAE: 1265.36, R²: 0.7300
  Val   - MSE: 11836999.28, RMSE: 3440.49, MAE: 1305.04, R²: 0.5922

Training Lasso...
Lasso Results:
  Train - MSE: 10186051.28, RMSE: 3191.56, MAE: 1195.12, R²: 0.7254
  Val   - MSE: 10884218.67, RMSE: 3299.12, MAE: 1165.89, R²: 0.6250
  Features selected by Lasso: 177/702

============================================================
MODEL COMPARISON:
============================================================
Ridge:
  Validation RMSE: 3440.49
  Validation R²: 0.5922
Lasso:
  Validation RMSE: 3299.12
  Validation R²: 0.6250

Best model: Lasso (Validation RMSE: 3299.12)

Loading original test data for Hospital_Id...
Making predictions on test set with Lasso...

Submission file created:
Shape: (500, 2)
Columns: ['Hospital_Id', 'Transport_Cost']

First few predictions:
            Hospital_Id  Transport_Cost
0          fffe33003400     -183.161599
1  fffe3700330036003600      434.719406
2  fffe3300390038003400     4768.350630
3      fffe310030003900     1070.714148
4  fffe3700330031003200     1424.710011

Prediction statistics:
Mean: 1563.56
Std: 25250.88
Min: -512308.44
Max: 164550.18

Submission saved to 'submission_polynomial.csv'

================================================================================
MODEL TRAINING WITH POLYNOMIAL FEATURES COMPLETE!
================================================================================

Final Results Summary:
Best model: Lasso
Polynomial degree: 2
Original features: 36
Polynomial features: 702
Submission file: submission_polynomial.csv (500 predictions)

Files created:
- submission_polynomial.csv

Training with polynomial features completed successfully!
(ml-env) ➜  mlnew uv run model2.py
Starting Ridge and Lasso model training with polynomial features...
================================================================================
Loading preprocessed data...
Original dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Creating polynomial features (degree=2)...
Fitting polynomial transformer on training data...
Transforming validation and test data...
After polynomial features:
X_train_poly: (4037, 9138)
X_val_poly: (713, 9138)
X_test_poly: (500, 9138)
Feature expansion: 36 -> 9138 features

Standardizing polynomial features...
Features standardized using StandardScaler

Training models with polynomial features...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 4284589.20, RMSE: 2069.92, MAE: 941.66, R²: 0.8845
  Val   - MSE: 28020387.32, RMSE: 5293.43, MAE: 1940.17, R²: 0.0347

Training Lasso...
^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C
^C^C^C^C^C^C^C^C^X^Z
[1]  + 385360 suspended  uv run model2.py
(ml-env) ➜  mlnew uv run model2.py
Starting Ridge and Lasso model training with polynomial features...
================================================================================
Loading preprocessed data...
Original dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Creating polynomial features (degree=2)...
Fitting polynomial transformer on training data...
Transforming validation and test data...
After polynomial features:
X_train_poly: (4037, 9138)
X_val_poly: (713, 9138)
X_test_poly: (500, 9138)
Feature expansion: 36 -> 9138 features

Standardizing polynomial features...
Features standardized using StandardScaler

Training models with polynomial features...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 7068302.70, RMSE: 2658.63, MAE: 1015.65, R²: 0.8095
  Val   - MSE: 13681757.90, RMSE: 3698.89, MAE: 1314.38, R²: 0.5287

Training Lasso...
Lasso Results:
  Train - MSE: 6120636.13, RMSE: 2473.99, MAE: 944.13, R²: 0.8350
  Val   - MSE: 15655708.62, RMSE: 3956.73, MAE: 1370.41, R²: 0.4607
  Features selected by Lasso: 592/9138

============================================================
MODEL COMPARISON:
============================================================
Ridge:
  Validation RMSE: 3698.89
  Validation R²: 0.5287
Lasso:
  Validation RMSE: 3956.73
  Validation R²: 0.4607

Best model: Ridge (Validation RMSE: 3698.89)

Loading original test data for Hospital_Id...
Making predictions on test set with Ridge...

Submission file created:
Shape: (500, 2)
Columns: ['Hospital_Id', 'Transport_Cost']

First few predictions:
            Hospital_Id  Transport_Cost
0          fffe33003400      432.707941
1  fffe3700330036003600      139.921781
2  fffe3300390038003400     6147.746904
3      fffe310030003900     -175.800322
4  fffe3700330031003200     1036.486918

Prediction statistics:
Mean: 1933.05
Std: 19817.37
Min: -381923.20
Max: 157613.39

Submission saved to 'submission_polynomial.csv'

Top 20 features by absolute coefficient value (Ridge):
 1. Equipment_Value Rural_Hospital_nan Transport_Method_Roadways: 343.3557
 2. Equipment_Value^2 Supplier_Reliability: -249.9693
 3. Equipment_Value Installation_Service_Yes Rural_Hospital_nan: 245.1404
 4. Base_Transport_Fee Supplier_Reliability^2: 210.7744
 5. Equipment_Type_Marble Equipment_Weight Supplier_Reliability: 204.7364
 6. Equipment_Value Hospital_Info_Wealthy Transport_Method_Airways: 192.6664
 7. Equipment_Height Equipment_Type_Stone Supplier_Reliability: 189.4542
 8. Equipment_Value Hospital_Info_Wealthy Urgent_Shipping_Yes: 183.1302
 9. Equipment_Value Hospital_Info_Working Class Urgent_Shipping_Yes: -181.3471
10. CrossBorder_Shipping_Yes Equipment_Type_Marble Equipment_Weight: 178.4588
11. Equipment_Value Equipment_Weight Supplier_Reliability: -177.8102
12. Equipment_Value^2 Installation_Service_No: -177.7268
13. Equipment_Value^2 Transport_Method_Roadways: -175.8290
14. Base_Transport_Fee Equipment_Height Supplier_Reliability: 175.3271
15. CrossBorder_Shipping_No Equipment_Value Transport_Method_Airways: 174.1858
16. Equipment_Value^2 Fragile_Equipment_No: -170.9791
17. Equipment_Height Equipment_Type_Marble Supplier_Reliability: 168.8697
18. Equipment_Height Equipment_Type_Stone Rural_Hospital_Yes: 165.4026
19. Base_Transport_Fee Equipment_Value Supplier_Reliability: 163.2812
20. Equipment_Value Supplier_Reliability Transport_Method_nan: 160.6783

================================================================================
MODEL TRAINING WITH POLYNOMIAL FEATURES COMPLETE!
================================================================================

Final Results Summary:
Best model: Ridge
Polynomial degree: 2
Original features: 36
Polynomial features: 9138
Submission file: submission_polynomial.csv (500 predictions)

Files created:
- submission_polynomial.csv

Training with polynomial features completed successfully!
(ml-env) ➜  mlnew uv run model2.py
Starting Ridge and Lasso model training with polynomial features...
================================================================================
Loading preprocessed data...
Original dataset shapes:
X_train: (4750, 36)
y_train: (4750,)
X_test: (500, 36)

Missing values - Train: 0, Test: 0

Splitting into train/validation (85%/15%)...
After split:
X_train_split: (4037, 36)
X_val: (713, 36)
y_train_split: (4037,)
y_val: (713,)

Creating polynomial features (degree=2)...
Fitting polynomial transformer on training data...
Transforming validation and test data...
After polynomial features:
X_train_poly: (4037, 9138)
X_val_poly: (713, 9138)
X_test_poly: (500, 9138)
Feature expansion: 36 -> 9138 features

Standardizing polynomial features...
Features standardized using StandardScaler

Training models with polynomial features...
============================================================

Training Ridge...
Ridge Results:
  Train - MSE: 7068302.70, RMSE: 2658.63, MAE: 1015.65, R²: 0.8095
  Val   - MSE: 13681757.90, RMSE: 3698.89, MAE: 1314.38, R²: 0.5287

Training Lasso...
Lasso Results:
  Train - MSE: 6120636.13, RMSE: 2473.99, MAE: 944.13, R²: 0.8350
  Val   - MSE: 15655708.62, RMSE: 3956.73, MAE: 1370.41, R²: 0.4607
  Features selected by Lasso: 592/9138

============================================================
MODEL COMPARISON:
============================================================
Ridge:
  Validation RMSE: 3698.89
  Validation R²: 0.5287
Lasso:
  Validation RMSE: 3956.73
  Validation R²: 0.4607

Best model: Ridge (Validation RMSE: 3698.89)

Loading original test data for Hospital_Id...
Making predictions on test set with Ridge...

Submission file created:
Shape: (500, 2)
Columns: ['Hospital_Id', 'Transport_Cost']

First few predictions:
            Hospital_Id  Transport_Cost
0          fffe33003400      432.707941
1  fffe3700330036003600      139.921781
2  fffe3300390038003400     6147.746904
3      fffe310030003900     -175.800322
4  fffe3700330031003200     1036.486918

Prediction statistics:
Mean: 1933.05
Std: 19817.37
Min: -381923.20
Max: 157613.39

Submission saved to 'submission_polynomial.csv'

Top 20 features by absolute coefficient value (Ridge):
 1. Equipment_Value Rural_Hospital_nan Transport_Method_Roadways: 343.3557
 2. Equipment_Value^2 Supplier_Reliability: -249.9693
 3. Equipment_Value Installation_Service_Yes Rural_Hospital_nan: 245.1404
 4. Base_Transport_Fee Supplier_Reliability^2: 210.7744
 5. Equipment_Type_Marble Equipment_Weight Supplier_Reliability: 204.7364
 6. Equipment_Value Hospital_Info_Wealthy Transport_Method_Airways: 192.6664
 7. Equipment_Height Equipment_Type_Stone Supplier_Reliability: 189.4542
 8. Equipment_Value Hospital_Info_Wealthy Urgent_Shipping_Yes: 183.1302
 9. Equipment_Value Hospital_Info_Working Class Urgent_Shipping_Yes: -181.3471
10. CrossBorder_Shipping_Yes Equipment_Type_Marble Equipment_Weight: 178.4588
11. Equipment_Value Equipment_Weight Supplier_Reliability: -177.8102
12. Equipment_Value^2 Installation_Service_No: -177.7268
13. Equipment_Value^2 Transport_Method_Roadways: -175.8290
14. Base_Transport_Fee Equipment_Height Supplier_Reliability: 175.3271
15. CrossBorder_Shipping_No Equipment_Value Transport_Method_Airways: 174.1858
16. Equipment_Value^2 Fragile_Equipment_No: -170.9791
17. Equipment_Height Equipment_Type_Marble Supplier_Reliability: 168.8697
18. Equipment_Height Equipment_Type_Stone Rural_Hospital_Yes: 165.4026
19. Base_Transport_Fee Equipment_Value Supplier_Reliability: 163.2812
20. Equipment_Value Supplier_Reliability Transport_Method_nan: 160.6783

================================================================================
MODEL TRAINING WITH POLYNOMIAL FEATURES COMPLETE!
================================================================================

Final Results Summary:
Best model: Ridge
Polynomial degree: 2
Original features: 36
Polynomial features: 9138
Submission file: submission_polynomial.csv (500 predictions)

Files created:
- submission_polynomial.csv

Training with polynomial features completed successfully!
